{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "768c6d20-991e-4943-b51b-746ce470c350",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1: Setup and Imports\n",
    "import gc\n",
    "from pyspark.ml.feature import VectorAssembler, FeatureHasher\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# 2: Data Loading & Preprocessing\n",
    "print(\"Loading NYC dataset...\")\n",
    "# Using the NYC table\n",
    "df = spark.table(\"workspace.capstone_project.nyc_model_ready\")\n",
    "df = df.filter(col(\"delay_indicator\").isNotNull())\n",
    "df.groupBy(\"delay_indicator\").count().show()\n",
    "\n",
    "# Preprocessing with Feature Hashing to prevent the 1GB overflow error\n",
    "categorical_cols = ['incident_category', 'season', 'unified_call_source', 'location_area']\n",
    "hasher = FeatureHasher(inputCols=categorical_cols, outputCol=\"categorical_features\", numFeatures=512)\n",
    "\n",
    "# Feature Assembly\n",
    "numeric_cols = ['hour', 'day_of_week', 'month', 'year', 'unified_alarm_level', \n",
    "                'calls_past_30min', 'calls_past_60min']\n",
    "assembler = VectorAssembler(inputCols=numeric_cols + [\"categorical_features\"], outputCol=\"features\")\n",
    "\n",
    "# 3: Training with Downsampling\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"delay_indicator\",\n",
    "    numTrees=50,\n",
    "    maxDepth=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[hasher, assembler, rf])\n",
    "\n",
    "print(\"Starting fit on NYC sample...\")\n",
    "model = pipeline.fit(train_df)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# 4: Evaluation and Saving\n",
    "# Generate predictions\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# AUC-ROC & PR-AUC (threshold-independent)\n",
    "roc_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"delay_indicator\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "auc = roc_evaluator.evaluate(predictions)\n",
    "print(f\"NYC Model AUC-ROC: {auc}\")\n",
    "\n",
    "pr_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"delay_indicator\",\n",
    "    metricName=\"areaUnderPR\"\n",
    ")\n",
    "auc_pr = pr_evaluator.evaluate(predictions)\n",
    "print(f\"NYC Model PR-AUC: {auc_pr}\")\n",
    "\n",
    "# Confusion Matrix (label-based)\n",
    "print(\"Confusion Matrix (Actual vs Predicted):\")\n",
    "predictions.groupBy(\"delay_indicator\", \"prediction\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"delay_indicator\", \"prediction\") \\\n",
    "    .show()\n",
    "\n",
    "# Precision / Recall / F1 (label-based)\n",
    "precision_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"delay_indicator\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedPrecision\"\n",
    ")\n",
    "\n",
    "recall_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"delay_indicator\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedRecall\"\n",
    ")\n",
    "\n",
    "f1_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"delay_indicator\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "precision = precision_eval.evaluate(predictions)\n",
    "recall = recall_eval.evaluate(predictions)\n",
    "f1 = f1_eval.evaluate(predictions)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Save model\n",
    "save_path = \"/Volumes/workspace/capstone_project/models/delay_classifier_nyc\"\n",
    "print(f\"Saving model to: {save_path}\")\n",
    "model.write().overwrite().save(save_path)\n",
    "\n",
    "# Clean up memory\n",
    "del model\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "train_delay_classifier",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
